import torch
import torchvision
from torchvision.models.detection import maskrcnn_resnet50_fpn
import cv2
import numpy as np
from torchvision.utils import draw_bounding_boxes
import argparse
from math import atan2, cos, sin, sqrt, pi
from PIL import Image

# Load pre-trained Mask R-CNN model
segmentation_model = maskrcnn_resnet50_fpn(pretrained=True)
segmentation_model.eval()

cap = cv2.VideoCapture(0)

while cap.isOpened():
    ret, frame = cap.read()
    
    # Convert frame to a PyTorch tensor
    frame_tensor = torchvision.transforms.ToTensor()(frame)
    
    # Add an extra dimension to represent the batch size (1 in this case)
    frame_tensor = frame_tensor.unsqueeze(0)
    
    # Move the tensor to the appropriate device (e.g., GPU if available)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    frame_tensor = frame_tensor.to(device)
    # Apply instance segmentation
    with torch.no_grad():
        predictions = segmentation_model(frame_tensor)
    # Retrieve the segmented image from the predictions
    test = predictions[0]['masks'].numpy()
    test1 = np.where(test>0.5, test, 0)
    test1 = (np.where(test1 == np.max(test1, axis = 0), 1, 0)).astype(np.uint8)
    segment_colors = np.random.randint(0, 255, size=(test1.shape[0], 3), dtype=np.uint8)
    segmented = np.zeros_like(frame)
    for i in range(test1.shape[0]):
        mask = test1[i, 0]  # Binary mask for the current segment
        color = segment_colors[i]  # Color for the current segment

        # Accumulate the colors for the current segment
        segmented[mask == 1] = color
        contours, _ = cv2.findContours(test1[i, 0], cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)

        for i, c in enumerate(contours):
            # Calculate the area of each contour
            area = cv2.contourArea(c)
            # Ignore contours that are too small or too large
            if area < 1e2 or 1e5 < area:
                continue

            # Draw each contour only for visualisation purposes
            # Find the orientation of each shape
            getOrientation(c, segmented)
    masked = cv2.cvtColor(segmented, cv2.COLOR_RGB2BGR)

    cv2.imshow('output', masked)
    cv2.waitKey()
    
    if cv2.waitKey(10) & 0xFF == ord('q'):
        break
        
cap.release()
cv2.destroyAllWindows()

def drawAxis(img, p_, q_, colour, scale):
    p = list(p_)
    q = list(q_)
    ## [visualization1]
    angle = atan2(p[1] - q[1], p[0] - q[0]) # angle in radians
    hypotenuse = sqrt((p[1] - q[1]) * (p[1] - q[1]) + (p[0] - q[0]) * (p[0] - q[0]))

    # Here we lengthen the arrow by a factor of scale
    q[0] = p[0] - scale * hypotenuse * cos(angle)
    q[1] = p[1] - scale * hypotenuse * sin(angle)
    cv2.line(img, (int(p[0]), int(p[1])), (int(q[0]), int(q[1])), colour, 1, cv2.LINE_AA)

    # create the arrow hooks
    p[0] = q[0] + 9 * cos(angle + pi / 4)
    p[1] = q[1] + 9 * sin(angle + pi / 4)
    cv2.line(img, (int(p[0]), int(p[1])), (int(q[0]), int(q[1])), colour, 1, cv2.LINE_AA)

    p[0] = q[0] + 9 * cos(angle - pi / 4)
    p[1] = q[1] + 9 * sin(angle - pi / 4)
    cv2.line(img, (int(p[0]), int(p[1])), (int(q[0]), int(q[1])), colour, 1, cv2.LINE_AA)
    ## [visualization1]

def getOrientation(pts, img):
    ## [pca]
    # Construct a buffer used by the pca analysis
    sz = len(pts)
    data_pts = np.empty((sz, 2), dtype=np.float64)
    for i in range(data_pts.shape[0]):
        data_pts[i,0] = pts[i,0,0]
        data_pts[i,1] = pts[i,0,1]

    # Perform PCA analysis
    mean = np.empty((0))
    mean, eigenvectors, eigenvalues = cv2.PCACompute2(data_pts, mean)

    # Store the center of the object
    cntr = (int(mean[0,0]), int(mean[0,1]))
    ## [pca]

    ## [visualization]
    # Draw the principal components
    cv2.circle(img, cntr, 3, (255, 0, 255), 2)
    p1 = (cntr[0] + 0.02 * eigenvectors[0,0] * eigenvalues[0,0], cntr[1] + 0.02 * eigenvectors[0,1] * eigenvalues[0,0])
    p2 = (cntr[0] - 0.02 * eigenvectors[1,0] * eigenvalues[1,0], cntr[1] - 0.02 * eigenvectors[1,1] * eigenvalues[1,0])
    drawAxis(img, cntr, p1, (0, 255, 0), 1)
    drawAxis(img, cntr, p2, (255, 255, 0), 5)

    angle = atan2(eigenvectors[0,1], eigenvectors[0,0]) # orientation in radians
    ## [visualization]

    return angle

